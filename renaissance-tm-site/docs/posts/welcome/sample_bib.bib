
@article{babieno_miss_2022,
	title = {{MIss} {RoBERTa} {WiLDe}: {Metaphor} {Identification} {Using} {Masked} {Language} {Model} with {Wiktionary} {Lexical} {Definitions}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {{MIss} {RoBERTa} {WiLDe}},
	url = {https://www.mdpi.com/2076-3417/12/4/2081},
	doi = {10.3390/app12042081},
	abstract = {Recent years have brought an unprecedented and rapid development in the field of Natural Language Processing. To a large degree this is due to the emergence of modern language models like GPT-3 (Generative Pre-trained Transformer 3), XLNet, and BERT (Bidirectional Encoder Representations from Transformers), which are pre-trained on a large amount of unlabeled data. These powerful models can be further used in the tasks that have traditionally been suffering from a lack of material that could be used for training. Metaphor identification task, which is aimed at automatic recognition of figurative language, is one of such tasks. The metaphorical use of words can be detected by comparing their contextual and basic meanings. In this work, we deliver the evidence that fully automatically collected dictionary definitions can be used as the optimal medium for retrieving the non-figurative word senses, which consequently may help improve the performance of the algorithms used in metaphor detection task. As the source of the lexical information, we use the openly available Wiktionary. Our method can be applied without changes to any other dataset designed for token-level metaphor detection given it is binary labeled. In the set of experiments, our proposed method (MIss RoBERTa WiLDe) outperforms or performs similarly well as the competing models on several datasets commonly chosen in the research on metaphor processing.},
	language = {en},
	number = {4},
	urldate = {2023-09-27},
	journal = {Applied Sciences},
	author = {Babieno, Mateusz and Takeshita, Masashi and Radisavljevic, Dusan and Rzepka, Rafal and Araki, Kenji},
	month = jan,
	year = {2022},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {figurative language, language models, lexical definitions, metaphor detection, RoBERTa, Sentence-BERT, Wiktionary},
	pages = {2081},
}

@article{babieno_miss_2022-1,
	title = {{MIss} {RoBERTa} {WiLDe}: {Metaphor} {Identification} {Using} {Masked} {Language} {Model} with {Wiktionary} {Lexical} {Definitions}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {{MIss} {RoBERTa} {WiLDe}},
	url = {https://www.mdpi.com/2076-3417/12/4/2081},
	doi = {10.3390/app12042081},
	abstract = {Recent years have brought an unprecedented and rapid development in the field of Natural Language Processing. To a large degree this is due to the emergence of modern language models like GPT-3 (Generative Pre-trained Transformer 3), XLNet, and BERT (Bidirectional Encoder Representations from Transformers), which are pre-trained on a large amount of unlabeled data. These powerful models can be further used in the tasks that have traditionally been suffering from a lack of material that could be used for training. Metaphor identification task, which is aimed at automatic recognition of figurative language, is one of such tasks. The metaphorical use of words can be detected by comparing their contextual and basic meanings. In this work, we deliver the evidence that fully automatically collected dictionary definitions can be used as the optimal medium for retrieving the non-figurative word senses, which consequently may help improve the performance of the algorithms used in metaphor detection task. As the source of the lexical information, we use the openly available Wiktionary. Our method can be applied without changes to any other dataset designed for token-level metaphor detection given it is binary labeled. In the set of experiments, our proposed method (MIss RoBERTa WiLDe) outperforms or performs similarly well as the competing models on several datasets commonly chosen in the research on metaphor processing.},
	language = {en},
	number = {4},
	urldate = {2023-09-27},
	journal = {Applied Sciences},
	author = {Babieno, Mateusz and Takeshita, Masashi and Radisavljevic, Dusan and Rzepka, Rafal and Araki, Kenji},
	month = jan,
	year = {2022},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {figurative language, language models, lexical definitions, metaphor detection, RoBERTa, Sentence-BERT, Wiktionary},
	pages = {2081},
}

@article{neuman_metaphor_2013,
	title = {Metaphor {Identification} in {Large} {Texts} {Corpora}},
	volume = {8},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3639214/},
	doi = {10.1371/journal.pone.0062343},
	abstract = {Identifying metaphorical language-use (e.g., sweet child) is one of the challenges facing natural language processing. This paper describes three novel algorithms for automatic metaphor identification. The algorithms are variations of the same core algorithm. We evaluate the algorithms on two corpora of Reuters and the New York Times articles. The paper presents the most comprehensive study of metaphor identification in terms of scope of metaphorical phrases and annotated corpora size. Algorithms’ performance in identifying linguistic phrases as metaphorical or literal has been compared to human judgment. Overall, the algorithms outperform the state-of-the-art algorithm with 71\% precision and 27\% averaged improvement in prediction over the base-rate of metaphors in the corpus.},
	number = {4},
	urldate = {2023-09-27},
	journal = {PLoS ONE},
	author = {Neuman, Yair and Assaf, Dan and Cohen, Yohai and Last, Mark and Argamon, Shlomo and Howard, Newton and Frieder, Ophir},
	month = apr,
	year = {2013},
	pmid = {23658625},
	pmcid = {PMC3639214},
	pages = {e62343},
	file = {PubMed Central Full Text PDF:/Users/call/Zotero/storage/BK2LJ94L/Neuman et al. - 2013 - Metaphor Identification in Large Texts Corpora.pdf:application/pdf},
}

@inproceedings{comtextcommabelowsa_miqa_2022,
	address = {Online only},
	title = {{MiQA}: {A} {Benchmark} for {Inference} on {Metaphorical} {Questions}},
	shorttitle = {{MiQA}},
	url = {https://aclanthology.org/2022.aacl-short.46},
	abstract = {We propose a benchmark to assess the capability of large language models to reason with conventional metaphors. Our benchmark combines the previously isolated topics of metaphor detection and commonsense reasoning into a single task that requires a model to make inferences by accurately selecting between the literal and metaphorical register. We examine the performance of state-of-the-art pre-trained models on binary-choice tasks and find a large discrepancy between the performance of small and very large models, going from chance to near-human level. We also analyse the largest model in a generative setting and find that although human performance is approached, careful multiple-shot prompting is required.},
	urldate = {2023-09-27},
	booktitle = {Proceedings of the 2nd {Conference} of the {Asia}-{Pacific} {Chapter} of the {Association} for {Computational} {Linguistics} and the 12th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Com{\textbackslash}textcommabelowsa, Iulia and Eisenschlos, Julian and Narayanan, Srini},
	month = nov,
	year = {2022},
	pages = {373--381},
	file = {Full Text PDF:/Users/call/Zotero/storage/U39WFEGG/Comtextcommabelowsa et al. - 2022 - MiQA A Benchmark for Inference on Metaphorical Qu.pdf:application/pdf},
}

@inproceedings{beigman_klebanov_different_2014,
	address = {Baltimore, MD},
	title = {Different {Texts}, {Same} {Metaphors}: {Unigrams} and {Beyond}},
	shorttitle = {Different {Texts}, {Same} {Metaphors}},
	url = {https://aclanthology.org/W14-2302},
	doi = {10.3115/v1/W14-2302},
	urldate = {2023-09-27},
	booktitle = {Proceedings of the {Second} {Workshop} on {Metaphor} in {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Beigman Klebanov, Beata and Leong, Ben and Heilman, Michael and Flor, Michael},
	month = jun,
	year = {2014},
	pages = {11--17},
	file = {Full Text PDF:/Users/call/Zotero/storage/VJBMBAX2/Beigman Klebanov et al. - 2014 - Different Texts, Same Metaphors Unigrams and Beyo.pdf:application/pdf},
}

@inproceedings{heintz_automatic_2013,
	address = {Atlanta, Georgia},
	title = {Automatic {Extraction} of {Linguistic} {Metaphors} with {LDA} {Topic} {Modeling}},
	url = {https://aclanthology.org/W13-0908},
	urldate = {2023-09-27},
	booktitle = {Proceedings of the {First} {Workshop} on {Metaphor} in {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Heintz, Ilana and Gabbard, Ryan and Srivastava, Mahesh and Barner, Dave and Black, Donald and Friedman, Majorie and Weischedel, Ralph},
	month = jun,
	year = {2013},
	pages = {58--66},
	file = {Full Text PDF:/Users/call/Zotero/storage/AX9S2NP5/Heintz et al. - 2013 - Automatic Extraction of Linguistic Metaphors with .pdf:application/pdf},
}

@inproceedings{ozbal_learning_2016,
	address = {Austin, Texas},
	title = {Learning to {Identify} {Metaphors} from a {Corpus} of {Proverbs}},
	url = {https://aclanthology.org/D16-1220},
	doi = {10.18653/v1/D16-1220},
	urldate = {2023-09-27},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Özbal, Gözde and Strapparava, Carlo and Tekiroğlu, Serra Sinem and Pighin, Daniele},
	month = nov,
	year = {2016},
	pages = {2060--2065},
	file = {Full Text PDF:/Users/call/Zotero/storage/3WZDL6G2/Özbal et al. - 2016 - Learning to Identify Metaphors from a Corpus of Pr.pdf:application/pdf},
}

@misc{eren_senmfk-split_2022,
	title = {{SeNMFk}-{SPLIT}: {Large} {Corpora} {Topic} {Modeling} by {Semantic} {Non}-negative {Matrix} {Factorization} with {Automatic} {Model} {Selection}},
	shorttitle = {{SeNMFk}-{SPLIT}},
	url = {http://arxiv.org/abs/2208.09942},
	doi = {10.48550/arXiv.2208.09942},
	abstract = {As the amount of text data continues to grow, topic modeling is serving an important role in understanding the content hidden by the overwhelming quantity of documents. One popular topic modeling approach is non-negative matrix factorization (NMF), an unsupervised machine learning (ML) method. Recently, Semantic NMF with automatic model selection (SeNMFk) has been proposed as a modification to NMF. In addition to heuristically estimating the number of topics, SeNMFk also incorporates the semantic structure of the text. This is performed by jointly factorizing the term frequency-inverse document frequency (TF-IDF) matrix with the co-occurrence/word-context matrix, the values of which represent the number of times two words co-occur in a predetermined window of the text. In this paper, we introduce a novel distributed method, SeNMFk-SPLIT, for semantic topic extraction suitable for large corpora. Contrary to SeNMFk, our method enables the joint factorization of large documents by decomposing the word-context and term-document matrices separately. We demonstrate the capability of SeNMFk-SPLIT by applying it to the entire artificial intelligence (AI) and ML scientific literature uploaded on arXiv.},
	urldate = {2023-09-27},
	publisher = {arXiv},
	author = {Eren, Maksim E. and Solovyev, Nick and Bhattarai, Manish and Rasmussen, Kim and Nicholas, Charles and Alexandrov, Boian S.},
	month = aug,
	year = {2022},
	note = {arXiv:2208.09942 [cs]},
	keywords = {Computer Science - Information Retrieval},
	annote = {Comment: Accepted at ACM Symposium on Document Engineering 2022 (DocEng 22), 2022},
	file = {arXiv Fulltext PDF:/Users/call/Zotero/storage/IEMZQQQU/Eren et al. - 2022 - SeNMFk-SPLIT Large Corpora Topic Modeling by Sema.pdf:application/pdf;arXiv.org Snapshot:/Users/call/Zotero/storage/BTP4KS5A/2208.html:text/html},
}

@misc{wu_towards_2023,
	title = {Towards the {TopMost}: {A} {Topic} {Modeling} {System} {Toolkit}},
	shorttitle = {Towards the {TopMost}},
	url = {http://arxiv.org/abs/2309.06908},
	abstract = {Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.},
	urldate = {2023-09-27},
	publisher = {arXiv},
	author = {Wu, Xiaobao and Pan, Fengjun and Luu, Anh Tuan},
	month = sep,
	year = {2023},
	note = {arXiv:2309.06908 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/call/Zotero/storage/344GJ6CL/2309.html:text/html;Full Text PDF:/Users/call/Zotero/storage/MYVSA7J5/Wu et al. - 2023 - Towards the TopMost A Topic Modeling System Toolk.pdf:application/pdf},
}

@misc{james_evaluating_2023,
	title = {Evaluating {Dynamic} {Topic} {Models}},
	url = {http://arxiv.org/abs/2309.08627},
	abstract = {There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension combining topic quality with the model's temporal consistency. We demonstrate the utility of the proposed measure by applying it to synthetic data and data from existing DTMs. We also conducted a human evaluation, which indicates that the proposed measure correlates well with human judgment. Our findings may help in identifying changing topics, evaluating different DTMs, and guiding future research in this area.},
	urldate = {2023-09-27},
	publisher = {arXiv},
	author = {James, Charu and Nagda, Mayank and Ghassemi, Nooshin Haji and Kloft, Marius and Fellenz, Sophie},
	month = sep,
	year = {2023},
	note = {arXiv:2309.08627 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/call/Zotero/storage/6F27K8E6/2309.html:text/html;Full Text PDF:/Users/call/Zotero/storage/W8ZTIQXB/James et al. - 2023 - Evaluating Dynamic Topic Models.pdf:application/pdf},
}

@article{batmanghelich_11_nodate,
	title = {11 : {CRF} + {Intro} to {Topic} {Models}},
	language = {en},
	author = {Batmanghelich, Kayhan and Yang, Anqi and He, Junxian},
	file = {Batmanghelich et al. - 11  CRF + Intro to Topic Models.pdf:/Users/call/Zotero/storage/PIH5JL6Z/Batmanghelich et al. - 11  CRF + Intro to Topic Models.pdf:application/pdf},
}
